# -*- coding: utf-8 -*-
"""
æ¯æ—¥ç®€æŠ¥è‡ªåŠ¨è„šæœ¬ (DeepSeek ç‰ˆ)
åŠŸèƒ½ï¼šæŠ“å–çœŸå®RSS/APIæ•°æ® -> DeepSeek V3 åˆ†æ -> å‘é€é‚®ä»¶
"""

import os
import smtplib
import ssl
import time
import feedparser
import requests
from email.message import EmailMessage
from datetime import datetime
from openai import OpenAI  # ä½¿ç”¨ OpenAI æ ‡å‡†åº“è°ƒç”¨ DeepSeek

# --- é…ç½®åŒºåŸŸ ---

# è¯»å–ç¯å¢ƒå˜é‡
DEEPSEEK_API_KEY = os.environ.get("DEEPSEEK_API_KEY")
EMAIL_SENDER = os.environ.get("EMAIL_SENDER")
EMAIL_PASSWORD = os.environ.get("EMAIL_APP_PASSWORD")
EMAIL_RECEIVER = os.environ.get("EMAIL_RECEIVER")

# æ•°æ®æºé…ç½®
DATA_SOURCES = {
    "tech": [
        "http://feeds.feedburner.com/TechCrunch/",
        "https://www.theverge.com/rss/index.xml",
        "https://36kr.com/feed", # åŠ ä¸€ä¸ªä¸­æ–‡æº
    ],
    "finance": [
        "https://finance.yahoo.com/news/rssindex",
        "http://feeds.marketwatch.com/marketwatch/topstories/"
    ],
    "papers": [
        "http://export.arxiv.org/rss/cs.AI",
        "http://export.arxiv.org/rss/cs.CL"
    ]
}

HF_DAILY_PAPERS_API = "https://huggingface.co/api/daily_papers"

# --- åŠŸèƒ½å‡½æ•° ---

def fetch_rss_data(urls, max_items=3):
    """æŠ“å– RSS æ•°æ®"""
    print(f"æ­£åœ¨æŠ“å– RSS æ•°æ®...")
    combined_text = ""
    for url in urls:
        try:
            # è®¾ç½®è¶…æ—¶ï¼Œé˜²æ­¢å¡æ­»
            feed = feedparser.parse(url)
            print(f"  - æˆåŠŸè¿æ¥: {feed.feed.get('title', url)}")
            for entry in feed.entries[:max_items]:
                title = entry.get('title', 'No Title')
                summary = entry.get('summary', '')[:200] # æˆªæ–­æ‘˜è¦
                link = entry.get('link', '')
                combined_text += f"- {title}\n  æ‘˜è¦: {summary}...\n  é“¾æ¥: {link}\n\n"
        except Exception as e:
            print(f"  x æŠ“å–å¤±è´¥ {url}: {e}")
    return combined_text

def fetch_hf_daily_papers():
    """æŠ“å– Hugging Face Daily Papers"""
    print("æ­£åœ¨æŠ“å– Hugging Face Daily Papers...")
    try:
        response = requests.get(HF_DAILY_PAPERS_API, timeout=10)
        if response.status_code == 200:
            data = response.json()
            text = "--- Hugging Face Daily Papers ---\n"
            for paper in data[:5]: 
                title = paper.get('title', 'No Title')
                summary = paper.get('summary', 'No summary')[:200].replace('\n', ' ')
                paper_id = paper.get('paper', {}).get('id', '')
                link = f"https://huggingface.co/papers/{paper_id}" if paper_id else "No Link"
                text += f"é¢˜ç›®: {title}\né“¾æ¥: {link}\næ‘˜è¦: {summary}...\n\n"
            return text
        else:
            return "æ— æ³•è·å– HF æ•°æ®ã€‚"
    except Exception as e:
        return f"è·å– Hugging Face æ•°æ®æ—¶å‡ºé”™: {e}"

def analyze_with_deepseek(tech_text, finance_text, paper_text):
    """è°ƒç”¨ DeepSeek è¿›è¡Œæ€»ç»“"""
    print("æ­£åœ¨å‘é€ç»™ DeepSeek è¿›è¡Œåˆ†æ...")

    if not DEEPSEEK_API_KEY:
        print("âŒ é”™è¯¯: æœªæ‰¾åˆ° DEEPSEEK_API_KEY")
        return None

    # åˆå§‹åŒ– DeepSeek å®¢æˆ·ç«¯ (ä½¿ç”¨ OpenAI SDK)
    client = OpenAI(
        api_key=DEEPSEEK_API_KEY,
        base_url="https://api.deepseek.com"
    )

    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç§‘æŠ€ä¸é‡‘èæƒ…æŠ¥åˆ†æå¸ˆã€‚è¯·æ ¹æ®ä»¥ä¸‹æŠ“å–åˆ°çš„åŸå§‹æ•°æ®ï¼Œä¸ºæˆ‘å†™ä¸€ä»½æ—¥æŠ¥ã€‚

    ã€è¦æ±‚ã€‘
    1. è¯­è¨€ï¼šä¸­æ–‡ã€‚
    2. æ ¼å¼ï¼šæ¸…æ™°çš„ Markdown æ ¼å¼ã€‚
    3. ç»“æ„ï¼š
       - ğŸ¦ é‡‘èå¸‚åœº (åˆ†æå¸‚åœºæƒ…ç»ªï¼Œé‡ç‚¹æ–°é—»)
       - ğŸš€ ç§‘æŠ€å‰æ²¿ (å¤§å‚åŠ¨æ€ï¼Œæ–°ç¡¬ä»¶/è½¯ä»¶)
       - ğŸ“‘ è®ºæ–‡é€Ÿé€’ (é‡ç‚¹ä»‹ç» Hugging Face å’Œ arXiv ä¸Šæœ‰ä»·å€¼çš„ AI è®ºæ–‡)
       - ğŸ’¡ æ·±åº¦æ´å¯Ÿ (åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œç»™å‡ºä¸€ä¸¤å¥ä½ çš„ç‹¬å®¶åˆ†æ)
    
    ã€åŸå§‹æ•°æ®ã€‘
    === ç§‘æŠ€æ–°é—» ===
    {tech_text[:4000]} 
    
    === é‡‘èæ–°é—» ===
    {finance_text[:4000]}
    
    === è®ºæ–‡æ•°æ® ===
    {paper_text[:4000]}
    """

    try:
        response = client.chat.completions.create(
            model="deepseek-chat",  # DeepSeek V3 æ¨¡å‹
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„ä¸“ä¸šç®€æŠ¥åŠ©æ‰‹ã€‚"},
                {"role": "user", "content": prompt},
            ],
            temperature=1.3, # ç¨å¾®å¢åŠ ä¸€ç‚¹åˆ›é€ æ€§
            stream=False
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"âŒ DeepSeek API è°ƒç”¨å¤±è´¥: {e}")
        return None

def send_email(subject, content):
    """å‘é€é‚®ä»¶"""
    if not EMAIL_SENDER or not EMAIL_PASSWORD or not EMAIL_RECEIVER:
        print("âŒ é”™è¯¯ï¼šç¼ºå°‘é‚®ä»¶é…ç½®ï¼Œæ— æ³•å‘é€ã€‚")
        return

    msg = EmailMessage()
    msg['Subject'] = subject
    msg['From'] = EMAIL_SENDER
    msg['To'] = EMAIL_RECEIVER
    msg.set_content(content)

    try:
        smtp_server = "smtp.qq.com" if "qq.com" in EMAIL_SENDER or "foxmail.com" in EMAIL_SENDER else "smtp.gmail.com"
        context = ssl.create_default_context()
        with smtplib.SMTP_SSL(smtp_server, 465, context=context) as server:
            server.login(EMAIL_SENDER, EMAIL_PASSWORD)
            server.send_message(msg)
            print("âœ… é‚®ä»¶å‘é€æˆåŠŸï¼")
    except Exception as e:
        print(f"âŒ é‚®ä»¶å‘é€å¤±è´¥: {e}")

# --- ä¸»ç¨‹åº ---

def main():
    print("--- å¯åŠ¨æ¯æ—¥ç®€æŠ¥ä»»åŠ¡ (DeepSeekç‰ˆ) ---")
    
    tech_data = fetch_rss_data(DATA_SOURCES["tech"])
    finance_data = fetch_rss_data(DATA_SOURCES["finance"])
    hf_data = fetch_hf_daily_papers()
    arxiv_data = fetch_rss_data(DATA_SOURCES["papers"])
    
    all_paper_data = hf_data + "\n" + arxiv_data

    briefing_content = analyze_with_deepseek(tech_data, finance_data, all_paper_data)
    
    if briefing_content:
        today = datetime.now().strftime("%Y-%m-%d")
        subject = f"ã€AIæ—¥æŠ¥ã€‘{today} ç§‘æŠ€é‡‘èä¸è®ºæ–‡ç®€æŠ¥"
        send_email(subject, briefing_content)
        print("ä»»åŠ¡å®Œæˆï¼Œé‚®ä»¶å·²å‘é€ã€‚")
    else:
        print("åˆ†æå¤±è´¥ï¼Œæœªå‘é€é‚®ä»¶ã€‚")

if __name__ == "__main__":
    main()